{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will use torch_geometric to predict the developpement of a graph of positions through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gille\\miniconda3\\envs\\geom\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric\n",
    "import torch\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.utils import to_networkx, from_networkx\n",
    "from torch_geometric.nn import radius_graph\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import glob\n",
    "\n",
    "import pickle\n",
    "import lzma\n",
    "\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"/home/nstillman/0_miscellaneous/sbi_model1\")\n",
    "sys.path.append('/home/nstillman/1_sbi_activematter/cpp_model')\n",
    "#import allium"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a graph of cells having their own positions and velocity.\n",
    "\n",
    "In the graph, we will first start by connecting all the edges, then maybe later make radius_graphs to reduce the cost of the pass through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from torch_geometric.data import Dataset\n",
    "\n",
    "#find /scratch/users/nstillman/data-cpp/train/ -name \"*fast4p.p\" -type f  | head | xargs du\n",
    "\"\"\"\n",
    "27804   ./p000_r004_sb015_2148010_b039_fast4p.p                                                                         \n",
    "33133   ./p013_r000_sb009_2147623_b071_fast4p.p                                                                         \n",
    "9628    ./p056_r000_sb040_2147623_b132_fast4p.p                                                                         \n",
    "23679   ./p029_r003_sb006_2148010_b038_fast4p.p                                                                         \n",
    "16676   ./p030_r000_sb038_2147623_b119_fast4p.p                                                                         \n",
    "39793   ./p019_r001_sb013_2147250_b028_fast4p.p                                                                         \n",
    "21402   ./p023_r000_sb018_2147623_b131_fast4p.p                                                                         \n",
    "22863   ./p001_r002_sb001_2148010_b026_fast4p.p                                                                         \n",
    "38547   ./p040_r000_sb000_2147623_b082_fast4p.p                                                                         \n",
    "23422   ./p058_r000_sb020_2147623_b134_fast4p.p\n",
    "\"\"\"\n",
    "\n",
    "class CellGraphDataset(Dataset):\n",
    "    def __init__(self, root, max_size, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        \n",
    "        self.paths = self.each_path(root, max_size)\n",
    "        \n",
    "    def _download(self):\n",
    "        pass\n",
    "\n",
    "    def _process(self):\n",
    "        pass\n",
    "\n",
    "    class each_path():\n",
    "        def __init__(self, root, max_size):\n",
    "            self.root = root\n",
    "            self.max_size = max_size\n",
    "            self._each_path = self.read()\n",
    "            \n",
    "        def read(self):\n",
    "            relative = [s.replace('\\\\', '/') for s in glob.glob(str(self.root) + '/*fast4p.p*')]\n",
    "            max_size = max(self.max_size, len(relative))\n",
    "            relative = relative[:max_size]\n",
    "            absolute = [osp.abspath(s) for s in relative]\n",
    "            return absolute\n",
    "\n",
    "        def fset(self, value):\n",
    "            self._each_path = value\n",
    "        \n",
    "        def fget(self):\n",
    "            return self._each_path\n",
    "        \n",
    "    def process_file(self, path):\n",
    "        print(path)\n",
    "        if path.endswith(\".p\") :\n",
    "            with open(path, 'rb') as f:\n",
    "                x = pickle.load(f)\n",
    "                \n",
    "        if path.endswith(\".pz\") :\n",
    "            with lzma.open(path, 'rb') as f:\n",
    "                x = pickle.load(f)\n",
    "                \n",
    "        else :\n",
    "            raise ValueError(\"File type not supported for path: \" + path)\n",
    "            \n",
    "        # Parameters of interest: \n",
    "        #Attraction force: \n",
    "        epsilon = x.param.pairatt[0][0]\n",
    "        # Persistence timescale \n",
    "        tau = x.param.tau[0]\n",
    "        # Active force\n",
    "        v0 = x.param.factive[0]\n",
    "\n",
    "        #cutoff distance defines the interaction radius. You can assume below:\n",
    "        cutoff = 2*(x.param.cutoffZ + 2*x.param.pairatt[0][0])\n",
    "        #Get position data\n",
    "        rval = x.rval\n",
    "        #Get time and number of cells from shape of position data\n",
    "        T = rval.shape[0]\n",
    "        N = rval.shape[1]\n",
    "\n",
    "\n",
    "        #ideally we would like to only have those connections but radius_graph doesn't work on GPU for some reason\n",
    "        edge_index = torch.tensor([radius_graph(rval[t], r=cutoff, batch=None, loop=False, max_num_neighbors=100) for t in range(T)])\n",
    "        \n",
    "        #though for now we will make a completely connected graph\n",
    "        #edges = torch.tensor([[i,j] for i in range(N) for j in range(N) if i!=j]).t()\n",
    "        \n",
    "        #distance between nodes where rval[t, i, :] is the position of cell i at time t\n",
    "        edges_attr =  torch.tensor([torch.norm(rval[t, edge_index[t, 0, :], :] - rval[t, edge_index[t, 1, :], :], dim=1) for t in range(T)])\n",
    "        \n",
    "        #we will add to rval dx and dy to get the velocity\n",
    "        rval = torch.cat((rval, torch.zeros((T, N, 2))), dim=2)\n",
    "        for t in range(T-1):\n",
    "            rval[t+1, :, 2:4] = rval[t+1, :, :2] - rval[t, :, :2]\n",
    "\n",
    "        return rval, edge_index, edges_attr\n",
    "\n",
    "        #construction of the graph\n",
    "        geom = [Data(x=torch.tensor(rval[t, :, :]), edge_index=edge_index, edge_attr=edges_attr[t, :]) for t in range(T)]\n",
    "\n",
    "        #save the list of graphs\n",
    "        return geom\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.paths.fget())\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = self.process_file(self.paths.fget()[idx])\n",
    "        \n",
    "    def dump_source(self, path):\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(self.paths.fget(), f)\n",
    "            \n",
    "    def overwrite_source(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            #set the property to the new list of paths\n",
    "            self.paths.fset(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length :  36\n",
      "Test data length :  10\n",
      "Validation data length :  9\n"
     ]
    }
   ],
   "source": [
    "path = \"data/\" #local\n",
    "#path = \"/scratch/users/nstillman/data-cpp/\" #remote\n",
    "\n",
    "data_train = CellGraphDataset(root=path + 'train', max_size=36)\n",
    "print(\"Training data length : \", data_train.len())\n",
    "\n",
    "data_test = CellGraphDataset(root=path + 'test', max_size=10)\n",
    "print(\"Test data length : \", data_test.len())\n",
    " \n",
    "data_val = CellGraphDataset(root=path + 'valid', max_size=10)\n",
    "print(\"Validation data length : \", data_val.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"sources\" not in os.listdir():\n",
    "    os.mkdir(\"sources\")\n",
    "\n",
    "if \"train_paths.pkl\" not in os.listdir(\"sources\"):\n",
    "    #first time running, dump the paths to a pickle file\n",
    "    data_train.dump_source(\"sources/train_paths.pkl\")\n",
    "else :\n",
    "    #overwrite the paths to the previous configuration\n",
    "    data_train.overwrite_source(\"sources/train_paths.pkl\")\n",
    "    \n",
    "if \"test_paths.pkl\" not in os.listdir(\"sources\"):\n",
    "    data_test.dump_source(\"sources/test_paths.pkl\")\n",
    "else :\n",
    "    data_test.overwrite_source(\"sources/test_paths.pkl\")\n",
    "    \n",
    "if \"val_paths.pkl\" not in os.listdir(\"sources\"):\n",
    "    data_val.dump_source(\"sources/val_paths.pkl\")\n",
    "else :\n",
    "    data_val.overwrite_source(\"sources/val_paths.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gille\\Desktop\\graph-displacement\\data\\train\\p000_r000_sb000_2147955_b045_fast4p.p\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'allium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[39m=\u001b[39m data_train\u001b[39m.\u001b[39;49mget(\u001b[39m0\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[2], line 99\u001b[0m, in \u001b[0;36mCellGraphDataset.get\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m---> 99\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_file(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpaths\u001b[39m.\u001b[39;49mfget()[idx])\n",
      "Cell \u001b[1;32mIn[2], line 54\u001b[0m, in \u001b[0;36mCellGraphDataset.process_file\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mif\u001b[39;00m path\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.p\u001b[39m\u001b[39m\"\u001b[39m) :\n\u001b[0;32m     53\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m---> 54\u001b[0m         x \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(f)\n\u001b[0;32m     56\u001b[0m \u001b[39mif\u001b[39;00m path\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.pz\u001b[39m\u001b[39m\"\u001b[39m) :\n\u001b[0;32m     57\u001b[0m     \u001b[39mwith\u001b[39;00m lzma\u001b[39m.\u001b[39mopen(path, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'allium'"
     ]
    }
   ],
   "source": [
    "data = data_train.get(0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to define the model that will be used :\n",
    "    > input \n",
    "        (1) Graph at a particular time t (nodes having x,y,dx,dy as attributes)\n",
    "        (2) Graphs up to a particular time [t-a, t] (nodes having x,y as attributes)\n",
    "    > output\n",
    "        (a) Graph at the immediate next time step t+1\n",
    "        (b) Graph [t, t+b]\n",
    "        (c) Graph at t+b\n",
    "    > graph size\n",
    "        (x) Fixed graph size to the most nodes possible (or above)\n",
    "        (y) Unbounded graph size\n",
    "            >> idea : graph walks\n",
    "            >> idea : sampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following model will do (1ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GraphEvolution(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels, heads, dropout=0.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        #we want the channels to be (x, y, vx, vy)\n",
    "        if (in_channels != out_channels):\n",
    "            raise ValueError(\"in_channels must be equal to out_channels\")\n",
    "        \n",
    "        self.conv  = GATv2Conv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
    "        self.post = torch.nn.Linear(heads*hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        #x is a tensor of shape (T, N, in_channels)\n",
    "        #for each time step, we will predict the next time step\n",
    "        #the last one is empty and will be filled with the prediction\n",
    "        \n",
    "        #the edge_attr is a tensor of shape (T, E)\n",
    "        #where E is the number of edges\n",
    "        \n",
    "        #edge_index is a tensor of shape (T, 2, E)\n",
    "        \n",
    "        #if this worked it would be great\n",
    "        #y = self.conv(x, edge_index, edge_attr)\n",
    "\n",
    "        #here T is treated as a batch dimension\n",
    "        for i in range(0, x.shape[0]):\n",
    "            # x[i] is a tensor of shape (N, in_channels)\n",
    "            y = self.conv(x[i], edge_index[i], edge_attr[i])\n",
    "            # y is a tensor of shape (N, heads*hidden_channels)\n",
    "            y = F.elu(y)\n",
    "            # different nodes will be considered as batches\n",
    "            y = self.post(y)\n",
    "            # y is a tensor of shape (N, out_channels)\n",
    "            x[i] = y + x[i]\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global losses\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def test(model, data, device) :\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    with torch.no_grad():\n",
    "        loss_sum = 0\n",
    "        for i in range(data.len()):\n",
    "            x, edge_index, edge_attr = data.get(i)\n",
    "            \n",
    "            random_number = random.randint(1, x.shape[0]-2)\n",
    "            \n",
    "            xshape = x.shape\n",
    "            \n",
    "            y = x[random_number+1].to(device)\n",
    "            x = x[random_number].to(device)\n",
    "            ei = edge_index[random_number].to(device)\n",
    "            ea = edge_attr[random_number].to(device)\n",
    "            \n",
    "            out = model(x.unsqueeze(0), ei.unsqueeze(0), ea.unsqueeze(0))\n",
    "            \n",
    "            loss = F.mse_loss(out, y.unsqueeze(0))\n",
    "            \n",
    "            loss_sum = loss_sum + loss.item()\n",
    "            \n",
    "        return loss_sum / data.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, data, device) :\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    for i in range(data.len()):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x, edge_index, edge_attr = data.get(i)\n",
    "        \n",
    "        x = x.to(device)\n",
    "        edge_index = edge_index.to(device)\n",
    "        edge_attr = edge_attr.to(device)\n",
    "        \n",
    "        #we don't want to predict the last step since we wouldn't have the data for the loss\n",
    "        #and for the first point we don't have the velocity\n",
    "        out = model(x[1:-1], edge_index[1:-1], edge_attr[1:-1])\n",
    "        \n",
    "        loss = F.mse_loss(out, x[2:])\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step(i)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(model, optimizer, scheduler, data_train, data_test, device, epoch):\n",
    "    for e in range(epoch):\n",
    "        model = train(model, optimizer, scheduler, data_train, device)\n",
    "            \n",
    "        test_loss = test(model, data_test, device)\n",
    "        \n",
    "        print(\"Epoch : \", e, \"Test loss : \", test_loss)\n",
    "        \n",
    "        losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphEvolution(4, 4, 32, 8, 0.0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=10, T_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class GraphingLoss():\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "        self.stop = False\n",
    "        self.timer = 0\n",
    "\n",
    "    def plot_and_reschedule(self):\n",
    "        plt.plot(losses)\n",
    "        plt.show()\n",
    "        if not self.stop:\n",
    "            threading.Timer(self.timer, self.plot_and_reschedule).start()\n",
    "            \n",
    "    def gstop(self):\n",
    "        self.stop = True\n",
    "        \n",
    "    def gstart(self, timer=10):\n",
    "        self.timer = timer\n",
    "        if (not self.timer or self.timer != int(self.timer)):\n",
    "            raise ValueError(\"timer must be a positive integer\")\n",
    "        \n",
    "        threading.Timer(self.timer, self.plot_and_reschedule).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "grapher = GraphingLoss()\n",
    "gstart = grapher.gstart(10)\n",
    "start(model, optimizer, scheduler, data_train, data_test, \"cuda\" if torch.cuda.is_available() else \"cpu\", epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c671acb9d3cf87d64ea7277f1f1b7981cda534cb27553b34f82b93fda7c98f17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
