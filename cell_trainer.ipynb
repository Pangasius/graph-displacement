{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will use torch_geometric to predict the developpement of a graph of positions through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI realized I am leaning towards this approach https://doi.org/10.1016/j.trc.2020.102635\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "I realized I am leaning towards this approach https://doi.org/10.1016/j.trc.2020.102635\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gille\\miniconda3\\envs\\geom\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using :  290\n",
      "Available :  3271\n",
      "True\n",
      "Could not import allium\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from genericpath import exists\n",
    "\n",
    "from cell_dataset import CellGraphDataset, load\n",
    "from cell_model import GraphEvolution, GraphEvolutionDiscr\n",
    "from cell_utils import GraphingLoss\n",
    "from cell_training import train, test_single, test_recursive, compute_parameters\n",
    "\n",
    "import os, psutil\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Using : \", process.memory_info().rss // 1000000)  # in megabytes \n",
    "print(\"Available : \", process.memory_info().vms  // 1000000)  # in megabytes \n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "#https://github.com/clovaai/AdamP\n",
    "from adamp import AdamP\n",
    "\n",
    "sys.path.append('/home/nstillman/1_sbi_activematter/cpp_model')\n",
    "try :\n",
    "    import allium\n",
    "except :\n",
    "    print(\"Could not import allium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a graph of cells having their own positions and velocity.\n",
    "\n",
    "In the graph, we will first start by connecting all the edges, then maybe later make radius_graphs to reduce the cost of the pass through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data not found\n"
     ]
    }
   ],
   "source": [
    "load_all =  True #load directly from a pickle\n",
    "pre_separated = False #if three subfolders already exist for train test and val\n",
    "\n",
    "override = False #make this true to always use the same ones\n",
    "\n",
    "extension = \"_open_ht_lv\"\n",
    "\n",
    "model_path = \"models/model\" + extension + \"_\"\n",
    "loss_path = \"models/loss\" + extension + \"_\"\n",
    "\n",
    "data_train, data_test, data_val = load(load_all, extension, pre_separated, override)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is data wrapped ?  False\n"
     ]
    }
   ],
   "source": [
    "#INFO : if bg_load is True, this starts the loading, if skipped, bg_loading will take place as soon as a get is called\n",
    "rval, edge_index, edge_attr, batch_edge, border, params = data_train.get(0)\n",
    "rval, edge_index, edge_attr, batch_edge, border, params = data_test.get(0)\n",
    "\n",
    "print(\"Is data wrapped ? \", data_train.wrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to define the model that will be used :\n",
    "    > input \n",
    "        (1) Graph at a particular time t (nodes having x,y,dx,dy as attributes)\n",
    "        (2) Graphs up to a particular time [t-a, t] (nodes having x,y as attributes)\n",
    "    > output\n",
    "        (a) Graph at the immediate next time step t+1\n",
    "        (b) Graph [t, t+b]\n",
    "        (c) Graph at t+b\n",
    "    > graph size\n",
    "        (x) Fixed graph size to the most nodes possible (or above)\n",
    "        (y) Unbounded graph size\n",
    "            >> idea : graph walks\n",
    "            >> idea : sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following model will do (1ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(model : GraphEvolution, optimizer : torch.optim.Optimizer, scheduler  : torch.optim.lr_scheduler._LRScheduler,\\\n",
    "          data_train : CellGraphDataset, data_test : CellGraphDataset, device : torch.device, epoch : int, offset : int, grapher : GraphingLoss, save=0, save_datasets=True):\n",
    "    for e in range(offset, offset + epoch):\n",
    "        \n",
    "        recursive = e > 10\n",
    "\n",
    "        model = train(model, optimizer, scheduler, data_train, device, e, process, max_epoch=offset+epoch, recursive=recursive)\n",
    "\n",
    "        #model.show_gradients()\n",
    "        \n",
    "        if(e == 0 and save_datasets) :\n",
    "            data_train.thread = None\n",
    "            data_test.thread = None\n",
    "            with open(\"data/training\" + extension + \".pkl\", 'wb') as f:\n",
    "                pickle.dump(data_train, f)\n",
    "            with open(\"data/testing \" + extension + \".pkl\", 'wb') as f:\n",
    "                pickle.dump(data_test, f)\n",
    "            print(\"Saved datasets\")\n",
    "        \n",
    "\n",
    "        test_loss_s = test_single(model, data_test, device, duration=16)\n",
    "        test_loss_r = test_recursive(model, data_test, device, duration=16)\n",
    "\n",
    "        print(\"Epoch : \", e, \"Test loss : \", test_loss_s, \"Test loss recursive : \", test_loss_r)\n",
    "\n",
    "        grapher.losses.append(test_loss_r)\n",
    "        grapher.losses.append(test_loss_s)\n",
    "\n",
    "        grapher.plot_losses()\n",
    "        \n",
    "        if (e%10 == 0) :      \n",
    "            all_params_out, all_params_true = compute_parameters(model, data_test, device, duration=-1)\n",
    "            grapher.plot_params(all_params_out, all_params_true, e, extension=extension)\n",
    "        \n",
    "        if (save and (e%save == 0 or e == epoch-1)) :\n",
    "            torch.save(model.state_dict(), model_path + str(e) + \".pt\")\n",
    "            with open(loss_path + str(e) + \".pkl\", 'wb') as f:\n",
    "                pickle.dump(grapher.losses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model\n"
     ]
    }
   ],
   "source": [
    "load = True\n",
    "\n",
    "epoch_to_load = 0\n",
    "\n",
    "model = GraphEvolution(in_channels=14, out_channels=4, hidden_channels=32, dropout=0.05, edge_dim=2, messages=10, wrap=data_train.wrap)\n",
    "#model = GraphEvolution(in_channels=9, out_channels=4, hidden_channels=32, dropout=0.01, edge_dim=2, messages=5, wrap=True)\n",
    "#model = GraphEvolutionDiscr(in_channels=9, out_channels=4, hidden_channels=16, dropout=0.01, edge_dim=2, messages=5, wrap=True)\n",
    "losses = []\n",
    "\n",
    "if exists(model_path + str(epoch_to_load) + \".pt\") and load :\n",
    "    with open(loss_path + str(epoch_to_load) + \".pkl\", 'rb') as f:\n",
    "        losses = pickle.load(f)\n",
    "    model.load_state_dict(torch.load(model_path + str(epoch_to_load) + \".pt\"))\n",
    "    print(\"Loaded model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using :  651\n",
      "Losses :  1\n",
      "Model :  GraphEvolution(\n",
      "  (encoder_resize): Linear(in_features=14, out_features=32, bias=True)\n",
      "  (encoder_resize2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (dropout): Dropout(p=0.05, inplace=False)\n",
      "        (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.05, inplace=False)\n",
      "        (dropout2): Dropout(p=0.05, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (dropout): Dropout(p=0.05, inplace=False)\n",
      "        (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.05, inplace=False)\n",
      "        (dropout2): Dropout(p=0.05, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (gat_resize): Linear(in_features=32, out_features=256, bias=True)\n",
      "  (gatv2s): ModuleList(\n",
      "    (0): GATv2Conv(256, 32, heads=8)\n",
      "    (1): GATv2Conv(256, 32, heads=8)\n",
      "    (2): GATv2Conv(256, 32, heads=8)\n",
      "    (3): GATv2Conv(256, 32, heads=8)\n",
      "    (4): GATv2Conv(256, 32, heads=8)\n",
      "    (5): GATv2Conv(256, 32, heads=8)\n",
      "    (6): GATv2Conv(256, 32, heads=8)\n",
      "    (7): GATv2Conv(256, 32, heads=8)\n",
      "    (8): GATv2Conv(256, 32, heads=8)\n",
      "    (9): GATv2Conv(256, 32, heads=8)\n",
      "  )\n",
      "  (gat_resize2): Linear(in_features=256, out_features=32, bias=True)\n",
      "  (transformer_decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (dropout): Dropout(p=0.05, inplace=False)\n",
      "        (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.05, inplace=False)\n",
      "        (dropout2): Dropout(p=0.05, inplace=False)\n",
      "        (dropout3): Dropout(p=0.05, inplace=False)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (dropout): Dropout(p=0.05, inplace=False)\n",
      "        (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
      "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.05, inplace=False)\n",
      "        (dropout2): Dropout(p=0.05, inplace=False)\n",
      "        (dropout3): Dropout(p=0.05, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder_resize): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (decoder_resize2): Linear(in_features=32, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Using : \", process.memory_info().rss // 1000000)  # in megabytes\n",
    "print(\"Losses : \", len(losses) // 2)\n",
    "print(\"Model : \", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#might want to investigate AdamP \n",
    "optimizer = AdamP(model.parameters(), lr=5e-4, betas=(0.9, 0.999), eps=1e-8, weight_decay=5e-3, delta=0.1, wd_ratio=0.1, nesterov=True)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=10, T_mult=2, eta_min=1e-12)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "grapher = GraphingLoss(losses)\n",
    "scheduler.step(len(losses) // 2)\n",
    "\n",
    "model = model.to(device)\n",
    "#data_train.to(device)\n",
    "#data_test.to(device)\n",
    "\n",
    "#all_params_out, all_params_true = compute_parameters(model.to(device), data_test, device, duration=8)\n",
    "#grapher.plot_params(all_params_out, all_params_true, epoch_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1 Test loss :  -4.114302656650543 Test loss recursive :  0.0024378935096319764\n",
      "Epoch :  2 Test loss :  -4.064601757526398 Test loss recursive :  0.0028750400798162445\n",
      "Epoch :  3 Test loss :  -3.99153635263443 Test loss recursive :  0.0033766000042669475\n",
      "Epoch :  4 Test loss :  -4.1348529410362245 Test loss recursive :  0.00150968996953452\n",
      "Epoch :  5 Test loss :  -4.1233647918701175 Test loss recursive :  0.001079014661081601\n",
      "Epoch :  6 Test loss :  -4.170844030380249 Test loss recursive :  0.00036177697693347\n",
      "Epoch :  7 Test loss :  -4.150682511329651 Test loss recursive :  0.0012480500277888495\n",
      "Epoch :  8 Test loss :  -4.12133127450943 Test loss recursive :  0.0017036578743136487\n",
      "Epoch :  9 Test loss :  -4.059589741230011 Test loss recursive :  0.0022280350839719177\n",
      "Current probability of recursive training :  0\n",
      "Epoch :  10 Test loss :  -4.0845848965644835 Test loss recursive :  0.0022622124815825373\n",
      "Epoch :  11 Test loss :  -4.139437003135681 Test loss recursive :  0.001052367085867445\n",
      "Epoch :  12 Test loss :  -4.143068060874939 Test loss recursive :  0.0006693020394595806\n",
      "Epoch :  13 Test loss :  -4.166329402923584 Test loss recursive :  0.0008255056965572294\n",
      "Epoch :  14 Test loss :  -4.168855018615723 Test loss recursive :  0.0009267137480492238\n",
      "Epoch :  15 Test loss :  -4.145162496566773 Test loss recursive :  0.0005255906769889406\n",
      "Current loss : 0.00, ... 413, / 800, Current memory usage : 820 MB, loaded 800     \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m start(model, optimizer, scheduler, data_train, data_test, device, \\\n\u001b[0;32m      2\u001b[0m         epochs, \u001b[39mlen\u001b[39;49m(losses) \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m \u001b[39m2\u001b[39;49m, grapher\u001b[39m=\u001b[39;49mgrapher, save\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, save_datasets\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m, in \u001b[0;36mstart\u001b[1;34m(model, optimizer, scheduler, data_train, data_test, device, epoch, offset, grapher, save, save_datasets)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(offset, offset \u001b[39m+\u001b[39m epoch):\n\u001b[0;32m      5\u001b[0m     recursive \u001b[39m=\u001b[39m e \u001b[39m>\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m----> 7\u001b[0m     model \u001b[39m=\u001b[39m train(model, optimizer, scheduler, data_train, device, e, process, max_epoch\u001b[39m=\u001b[39;49moffset\u001b[39m+\u001b[39;49mepoch, recursive\u001b[39m=\u001b[39;49mrecursive)\n\u001b[0;32m      9\u001b[0m     \u001b[39m#model.show_gradients()\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[39mif\u001b[39;00m(e \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m save_datasets) :\n",
      "File \u001b[1;32mc:\\Users\\gille\\Desktop\\graph-displacement\\cell_training.py:208\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, scheduler, data, device, epoch, process, max_epoch, recursive)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, GraphEvolutionDiscr) \u001b[39mor\u001b[39;00m condition :\n\u001b[0;32m    207\u001b[0m     duration \u001b[39m=\u001b[39m\u001b[39mint\u001b[39m((epoch \u001b[39m/\u001b[39m max_epoch) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m)\n\u001b[1;32m--> 208\u001b[0m     loss, _, _ \u001b[39m=\u001b[39m run_single_recursive(model, data, i, device, duration\u001b[39m=\u001b[39;49mduration, grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \n\u001b[0;32m    210\u001b[0m \u001b[39melse\u001b[39;00m :\n\u001b[0;32m    211\u001b[0m     duration \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gille\\Desktop\\graph-displacement\\cell_training.py:138\u001b[0m, in \u001b[0;36mrun_single_recursive\u001b[1;34m(model, data, i, device, duration, output, grad)\u001b[0m\n\u001b[0;32m    134\u001b[0m     duration \u001b[39m=\u001b[39m xshape[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m    136\u001b[0m \u001b[39mfor\u001b[39;00m current_time \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m duration) :\n\u001b[1;32m--> 138\u001b[0m     input_x \u001b[39m=\u001b[39m model(input_x\u001b[39m.\u001b[39;49mto(device), edge_index\u001b[39m.\u001b[39;49mto(device), edge_attr\u001b[39m.\u001b[39;49mto(device), params)\n\u001b[0;32m    140\u001b[0m     out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((out, input_x), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    142\u001b[0m     \u001b[39m#skip the following if on the last step\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gille\\miniconda3\\envs\\geom\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\gille\\Desktop\\graph-displacement\\cell_model.py:76\u001b[0m, in \u001b[0;36mGraphEvolution.forward\u001b[1;34m(self, x, edge_index, edge_attr, params)\u001b[0m\n\u001b[0;32m     73\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgat_resize2(y)\u001b[39m.\u001b[39mreshape(xshape[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39mxshape[\u001b[39m1\u001b[39m], \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_channels)\n\u001b[0;32m     75\u001b[0m \u001b[39m# different nodes will be considered as batches\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_decoder(y, encoded)\u001b[39m.\u001b[39mreshape(xshape[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39mxshape[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_channels)\n\u001b[0;32m     78\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder_resize(y)\n\u001b[0;32m     79\u001b[0m y \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mgelu(y)\n",
      "File \u001b[1;32mc:\\Users\\gille\\miniconda3\\envs\\geom\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\gille\\miniconda3\\envs\\geom\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:291\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    288\u001b[0m output \u001b[39m=\u001b[39m tgt\n\u001b[0;32m    290\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> 291\u001b[0m     output \u001b[39m=\u001b[39m mod(output, memory, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask,\n\u001b[0;32m    292\u001b[0m                  memory_mask\u001b[39m=\u001b[39;49mmemory_mask,\n\u001b[0;32m    293\u001b[0m                  tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask,\n\u001b[0;32m    294\u001b[0m                  memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask)\n\u001b[0;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32mc:\\Users\\gille\\miniconda3\\envs\\geom\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\gille\\miniconda3\\envs\\geom\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:576\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    574\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm3(x))\n\u001b[0;32m    575\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 576\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, tgt_mask, tgt_key_padding_mask))\n\u001b[0;32m    577\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mha_block(x, memory, memory_mask, memory_key_padding_mask))\n\u001b[0;32m    578\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm3(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n",
      "File \u001b[1;32mc:\\Users\\gille\\miniconda3\\envs\\geom\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:585\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._sa_block\u001b[1;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sa_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor,\n\u001b[0;32m    584\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 585\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(x, x, x,\n\u001b[0;32m    586\u001b[0m                        attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[0;32m    587\u001b[0m                        key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[0;32m    588\u001b[0m                        need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    589\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
      "File \u001b[1;32mc:\\Users\\gille\\miniconda3\\envs\\geom\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\gille\\miniconda3\\envs\\geom\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1153\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[0;32m   1142\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1143\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[0;32m   1144\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         q_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_proj_weight, k_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_proj_weight,\n\u001b[0;32m   1151\u001b[0m         v_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_proj_weight, average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights)\n\u001b[0;32m   1152\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1153\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[0;32m   1154\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[0;32m   1155\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[0;32m   1156\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[0;32m   1157\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m   1158\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[0;32m   1159\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask, need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[0;32m   1160\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask, average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights)\n\u001b[0;32m   1161\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[0;32m   1162\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32mc:\\Users\\gille\\miniconda3\\envs\\geom\\lib\\site-packages\\torch\\nn\\functional.py:5179\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)\u001b[0m\n\u001b[0;32m   5174\u001b[0m     dropout_p \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m   5176\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m   5177\u001b[0m \u001b[39m# (deep breath) calculate attention and out projection\u001b[39;00m\n\u001b[0;32m   5178\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m-> 5179\u001b[0m attn_output, attn_output_weights \u001b[39m=\u001b[39m _scaled_dot_product_attention(q, k, v, attn_mask, dropout_p)\n\u001b[0;32m   5180\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(tgt_len \u001b[39m*\u001b[39m bsz, embed_dim)\n\u001b[0;32m   5181\u001b[0m attn_output \u001b[39m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "File \u001b[1;32mc:\\Users\\gille\\miniconda3\\envs\\geom\\lib\\site-packages\\torch\\nn\\functional.py:4860\u001b[0m, in \u001b[0;36m_scaled_dot_product_attention\u001b[1;34m(q, k, v, attn_mask, dropout_p)\u001b[0m\n\u001b[0;32m   4858\u001b[0m     attn \u001b[39m=\u001b[39m dropout(attn, p\u001b[39m=\u001b[39mdropout_p)\n\u001b[0;32m   4859\u001b[0m \u001b[39m# (B, Nt, Ns) x (B, Ns, E) -> (B, Nt, E)\u001b[39;00m\n\u001b[1;32m-> 4860\u001b[0m output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbmm(attn, v)\n\u001b[0;32m   4861\u001b[0m \u001b[39mreturn\u001b[39;00m output, attn\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start(model, optimizer, scheduler, data_train, data_test, device, \\\n",
    "        epochs, len(losses) // 2, grapher=grapher, save=10, save_datasets=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
