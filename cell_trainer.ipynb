{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will use torch_geometric to predict the developpement of a graph of positions through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI realized I am leaning towards this approach https://doi.org/10.1016/j.trc.2020.102635\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "I realized I am leaning towards this approach https://doi.org/10.1016/j.trc.2020.102635\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using :  544\n",
      "Available :  43953\n",
      "True\n",
      "Cannot import zuko. Continuing without prior\n",
      "No module named 'pycapmd'\n",
      "Cannot import simulator\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from genericpath import exists\n",
    "\n",
    "from cell_dataset import CellGraphDataset, loadDataset\n",
    "from cell_model import Gatv2Predictor\n",
    "from cell_utils import GraphingLoss\n",
    "from cell_training import train, test_single, compute_parameters_draw\n",
    "\n",
    "import os, psutil\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Using : \", process.memory_info().rss // 1000000)  # in megabytes \n",
    "print(\"Available : \", process.memory_info().vms  // 1000000)  # in megabytes \n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "#https://github.com/clovaai/AdamP\n",
    "from adamp import AdamP\n",
    "\n",
    "sys.path.append('/home/nstillman/1_sbi_activematter/cpp_model')\n",
    "try :\n",
    "    import allium\n",
    "except :\n",
    "    print(\"Could not import allium\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a graph of cells having their own positions and velocity.\n",
    "\n",
    "In the graph, we will first start by connecting all the edges, then maybe later make radius_graphs to reduce the cost of the pass through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_open_lt_lv_2_64_relative_laplace_mean\n"
     ]
    }
   ],
   "source": [
    "load_all =  True #load directly from a pickle\n",
    "pre_separated = False #if three subfolders already exist for train test and val\n",
    "\n",
    "override = False #make this true to always use the same ones\n",
    "\n",
    "extension = \"_open_lt_lv\"\n",
    "number_of_messages = 2\n",
    "size_of_messages = 64\n",
    "absolute = 0\n",
    "epochs = 201\n",
    "distrib = \"laplace\"\n",
    "aggr = \"mean\"\n",
    "\n",
    "name_complete = extension + \"_\" + str(number_of_messages) + \"_\" + str(size_of_messages) + \"_\" + (\"absolute\" if absolute else \"relative\") + \"_\" + distrib + \"_\" + aggr\n",
    "\n",
    "print(name_complete)\n",
    "\n",
    "model_path = \"models/model\" + name_complete\n",
    "loss_path = \"models/loss\" + name_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data not found\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test, data_val = loadDataset(load_all, extension, pre_separated, override)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([99, 100, 5])\n",
      "tensor([17., 10., 11.,  9., 16.,  7.,  6.,  6.,  8.,  9.,  6.,  6., 10., 10.,\n",
      "         6., 13., 12., 13., 15., 11.,  9., 10., 15.,  9.,  8., 10., 12.,  6.,\n",
      "        11., 13.,  7.,  7.,  8.,  9., 10., 15.,  9.,  8., 12.,  9., 12.,  9.,\n",
      "        13., 11.,  7., 16., 10., 12.,  9., 10.,  7., 13., 12., 13., 12., 11.,\n",
      "        10., 15., 13.,  8., 11.,  6.,  4., 12., 10.,  8., 13., 11.,  7., 12.,\n",
      "         6.,  7., 10., 12., 12., 10., 10.,  6., 10., 12., 12.,  7., 14.,  6.,\n",
      "         5.,  4.,  6., 11., 10., 10.,  8.,  8., 15., 12.,  5., 10., 15., 11.,\n",
      "        12.,  9.])\n"
     ]
    }
   ],
   "source": [
    "data_point = data_train.get(0, -1)\n",
    "print(data_point[1].shape)\n",
    "print(data_point[1][1,:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val, edge_index, edge_attr = data_train.get_edges(data_point[1][1,:,:2].cpu(), 10, False, masks=None, previous=data_point[1][0,:,:2].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 5])\n",
      "tensor([[17., 10., 11.,  9., 16.,  7.,  6.,  6.,  8.,  9.,  6.,  6., 10., 10.,\n",
      "          6., 13., 12., 13., 15., 11.,  9., 10., 15.,  9.,  8., 10., 12.,  6.,\n",
      "         11., 13.,  7.,  7.,  8.,  9., 10., 15.,  9.,  8., 12.,  9., 12.,  9.,\n",
      "         13., 11.,  7., 16., 10., 12.,  9., 10.,  7., 13., 12., 13., 12., 11.,\n",
      "         10., 15., 13.,  8., 11.,  6.,  4., 12., 10.,  8., 13., 11.,  7., 12.,\n",
      "          6.,  7., 10., 12., 12., 10., 10.,  6., 10., 12., 12.,  7., 14.,  6.,\n",
      "          5.,  4.,  6., 11., 10., 10.,  8.,  8., 15., 12.,  5., 10., 15., 11.,\n",
      "         12.,  9.]])\n"
     ]
    }
   ],
   "source": [
    "print(new_val.shape)\n",
    "print(new_val[:,:,4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to define the model that will be used :\n",
    "    > input \n",
    "        (1) Graph at a particular time t (nodes having x,y,dx,dy as attributes)\n",
    "        (2) Graphs up to a particular time [t-a, t] (nodes having x,y as attributes)\n",
    "    > output\n",
    "        (a) Graph at the immediate next time step t+1\n",
    "        (b) Graph [t, t+b]\n",
    "        (c) Graph at t+b\n",
    "    > graph size\n",
    "        (x) Fixed graph size to the most nodes possible (or above)\n",
    "        (y) Unbounded graph size\n",
    "            >> idea : graph walks\n",
    "            >> idea : sampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following model will do (1ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(model : Gatv2Predictor, optimizer : torch.optim.Optimizer, scheduler  : torch.optim.lr_scheduler._LRScheduler,\\\n",
    "          data_train : CellGraphDataset, data_test : CellGraphDataset, device : torch.device, epoch : int, offset : int, grapher : GraphingLoss, save=0, save_datasets=True):\n",
    "    \n",
    "    loss_history_test_recursive = {\"loss_mean\" : [], \"loss_log\" : [], \"loss\" : []}\n",
    "    loss_history_train = {\"loss\" : []}\n",
    "    for e in range(offset, offset + epoch):\n",
    "\n",
    "        train_loss = train(model, optimizer, scheduler, data_train, device, e, process, max_epoch=offset+epoch, distrib=distrib, aggr=aggr)\n",
    "        loss_history_train[\"loss\"] += train_loss\n",
    "\n",
    "        #model.show_gradients()\n",
    "        \n",
    "        if(e == 0 and save_datasets) :\n",
    "            data_train.thread = None\n",
    "            data_test.thread = None\n",
    "            with open(\"data/training\" + extension + \".pkl\", 'wb') as f:\n",
    "                pickle.dump(data_train, f)\n",
    "            with open(\"data/testing\" + extension + \".pkl\", 'wb') as f:\n",
    "                pickle.dump(data_test, f)\n",
    "            print(\"Saved datasets\")\n",
    "        \n",
    "        test_loss_r = test_single(model, data_test, device, loss_history_test_recursive, duration=0, distrib=distrib, aggr=aggr)\n",
    "\n",
    "        print(\"Epoch : \", e, \"Test loss recursive : \", test_loss_r)\n",
    "\n",
    "        grapher.plot_losses(title=\"Testing recursive\", data=loss_history_test_recursive, length=min(50, len(data_test)), extension=name_complete + \"_\") \n",
    "        grapher.plot_losses(title=\"Training\", data=loss_history_train, length=len(data_train), extension=name_complete + \"_\")\n",
    "        \n",
    "        if (e%save == 0) :    \n",
    "            all_params_out, all_params_true = compute_parameters_draw(model, data_test, device, duration=-1, distrib=distrib)\n",
    "            grapher.plot_params(all_params_out, all_params_true, e, extension=name_complete)\n",
    "        \n",
    "        if (save and (e%save == 0 or e == epoch-1)) :\n",
    "            torch.save(model.state_dict(), model_path + str(e) + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = False\n",
    "\n",
    "epoch_to_load = 0\n",
    "\n",
    "model = Gatv2Predictor(in_channels=12, out_channels=8, hidden_channels=size_of_messages, dropout=0.05, edge_dim=2, messages=number_of_messages, wrap=data_train.wrap, absolute=absolute)\n",
    "#model = Gatv2Predictor(in_channels=9, out_channels=4, hidden_channels=32, dropout=0.01, edge_dim=2, messages=5, wrap=True)\n",
    "#model = Gatv2PredictorDiscr(in_channels=9, out_channels=4, hidden_channels=16, dropout=0.01, edge_dim=2, messages=5, wrap=True)\n",
    "#model = ConvPredictor(in_channels=16, out_channels=8, hidden_channels=size_of_messages, dropout=0.05, edge_dim=2, messages=number_of_messages, wrap=data_train.wrap, absolute=absolute, heads=4)\n",
    "\n",
    "if exists(model_path + str(epoch_to_load) + \".pt\") and load :\n",
    "    model.load_state_dict(torch.load(model_path + str(epoch_to_load) + \".pt\"))\n",
    "    print(\"Loaded model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#might want to investigate AdamP \n",
    "optimizer = AdamP(model.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-3, weight_decay=5e-3, delta=0.1, wd_ratio=0.1, nesterov=True)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapher = GraphingLoss()\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss : -1.33, ... 294, / 900, Current memory usage : 6647 MB, loaded 900    \r"
     ]
    }
   ],
   "source": [
    "start(model, optimizer, scheduler, data_train, data_test, device, \\\n",
    "        epochs, epoch_to_load, grapher=grapher, save=50, save_datasets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.]],\n",
      "\n",
      "        [[3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.]],\n",
      "\n",
      "        [[3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.]],\n",
      "\n",
      "        [[3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.]],\n",
      "\n",
      "        [[3.],\n",
      "         [3.],\n",
      "         [3.],\n",
      "         [3.]]])\n",
      "tensor([[ 0, 16, 12, 17,  1, 13, 14,  2, 10, 11, 15, 19,  0, 16, 12, 17,  1, 13,\n",
      "         14,  2, 10, 11, 15, 19,  0, 16, 12, 17,  1, 13, 14,  2, 10, 11, 15, 19,\n",
      "          0, 16, 12, 17,  1, 13, 14,  2, 10, 11, 15, 19,  0, 16, 12, 17,  1, 13,\n",
      "         14,  2, 10, 11, 15, 19],\n",
      "        [ 0,  0,  0,  1,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,  4,  5,  5,  5,\n",
      "          6,  6,  6,  7,  7,  7,  8,  8,  8,  9,  9,  9, 10, 10, 10, 11, 11, 11,\n",
      "         12, 12, 12, 13, 13, 13, 14, 14, 14, 15, 15, 15, 16, 16, 16, 17, 17, 17,\n",
      "         18, 18, 18, 19, 19, 19]])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import knn_graph\n",
    "import torch\n",
    "\n",
    "square = torch.tensor([[0,0], [0,1], [1,2], [1,1]], dtype=torch.float)\n",
    "\n",
    "square_repeter = square.unsqueeze(0).repeat(5,1,1)\n",
    "\n",
    "edge_index = knn_graph(square_repeter.view(-1,2), k = 3, loop=True, flow=\"source_to_target\")\n",
    "\n",
    "T = square_repeter.shape[0]\n",
    "N = square_repeter.shape[1]\n",
    "\n",
    "degree = torch.zeros((T,N,1))\n",
    "for i in range(T) :\n",
    "    for j in range(N) :\n",
    "        degree[i, j, 0] = torch.sum(edge_index[1, :] == i*N+j)\n",
    "\n",
    "print(degree)\n",
    "\n",
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3, 4])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1,2,3,4,5,6,7,8,9,10,11,12]).view(1,3,4).repeat(15,1,1).to(torch.float)\n",
    "\n",
    "\n",
    "print(a[-6:].shape)\n",
    "\n",
    "print(a.mean(dim=(0,1)).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
